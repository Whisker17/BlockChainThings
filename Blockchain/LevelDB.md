# LevelDB

**一句话说，LevelDB是一款基于LSM树的持久化存储的KV数据库，具有极佳的写功能。**

LSM树的核心思想就是**放弃部分读的性能，换取最大的写入能力**。

LSM树写性能极高的原理，简单地来说就是**尽量减少随机写的次数**。对于每次写入操作，并不是直接将最新的数据驻留在磁盘中，而是将其拆分成**（1）一次日志文件的顺序写（2）一次内存中的数据插入**。LevelDB正是实践了这种思想，将数据首先更新在内存中，当内存中的数据达到一定的阈值，将这部分数据真正刷新到磁盘文件中，因而获得了极高的写性能

## 整体架构

![LevelDB_1](./pics/LevelDB_1.png)

如上图所示，LevelDB共有六个成分组成：

1. Memtable
2. Immutable memtable
3. Log
4. Sstable
5. Manifest
6. Current

## 基本概念

### Memtable

DB数据在内存中的存储方式，写操作会先写入memtable，memtable是处在内存中的，所以效率非常高，但是由于内存容量是有限的，并且价格比较贵，所以我们会在达到阈值（默认为4MB）之后进行一个持久化的过程，变成只读的memtable(**immutable memtable**)，相关内容我们在下文继续介绍。

* **SkipList**

  SkipList本质上也是一种查找结构，用于解决算法中的查找问题，即根据给定的key，快速查到他所在的位置（或者对应的value）。

  SkipList，顾名思义，是一个list，事实上，它是在有序链表的基础上发展起来的。

  我们首先先来看一个有序链表：

  ![SkipList_1](./pics/SkipList_1.jpg)

  在这样的链表中，我们去查询某个数据的话，需要的是从头开始遍历，时间复杂度为O(n)。

  假如我们每相邻两个节点增加一个指针，让指针指向下下个节点，如下图：

  ![SkipList_2](./pics/SkipList_2.png)

  那么，在新的一层中，节点数就会下降到原先的一半（即7,19,26），还是从头开始遍历，但是数量减少了。当我们想要查找某个数据时，先沿着新的链表查询，当碰到比待查询数据大的节点时，再回到原来的节点去查询，例如我们想要查找23，查询路径即为红线：

  ![SkipList_2](./pics/SkipList_3.png)

  同样的，我们还可以继续再多建一层链表，进一步减少查询的次数。可以想象，当链表足够长的时候，这种多层链表的查找方式能让我们跳过很多下层节点，大大加快查找的速度。

  实际上，按照上面生成链表的方式，上面每一层链表的节点个数，是下面一层的节点个数的一半，这样查找过程就非常类似于一个**二分查找**，使得查找的时间复杂度可以降低到O(log n)。但是，**这种方法在插入数据的时候有很大的问题**。新插入一个节点之后，就会打乱上下相邻两层链表上节点个数严格的2:1的对应关系。如果要维持这种对应关系，就必须把新插入的节点后面的所有节点（也包括新插入的节点）重新进行调整，这会让时间复杂度重新蜕化成O(n)。删除数据也有同样的问题。

  SkipList为了避免这一问题，**它不要求上下相邻两层链表之间的节点个数有严格的对应关系**，而是为每个节点随机出一个层数(level)。比如，一个节点随机出的层数是3，那么就把它链入到第1层到第3层这三层链表中。为了表达清楚，下图展示了如何通过一步步的插入操作从而形成一个SkipList的过程：

  ![SkipList_2](./pics/SkipList_4.png)

  * **SkipList和平衡树、哈希表的比较**
    - **SkipList和各种平衡树（如AVL、红黑树等）的元素是有序排列的，而哈希表不是有序的。**因此，在哈希表上只能做单个key的查找，不适宜做范围查找。所谓范围查找，指的是查找那些大小在指定的两个值之间的所有节点。
    - 在做范围查找的时候，平衡树比SkipList操作要复杂。在平衡树上，我们找到指定范围的小值之后，还需要以中序遍历的顺序继续寻找其它不超过大值的节点。如果不对平衡树进行一定的改造，这里的中序遍历并不容易实现。而在SkipList上进行范围查找就非常简单，只需要在找到小值之后，对第1层链表进行若干步的遍历就可以实现。
    - 平衡树的插入和删除操作可能引发子树的调整，逻辑复杂，而SkipList的插入和删除只需要修改相邻节点的指针，操作简单又快速。
    - 从内存占用上来说，SkipList比平衡树更灵活一些。**一般来说，平衡树每个节点包含2个指针（分别指向左右子树），而SkipList每个节点包含的指针数目平均为1/(1-p)，**具体取决于参数p的大小。如果像Redis里的实现一样，取p=1/4，那么平均每个节点包含1.33个指针，比平衡树更有优势。
    - 查找单个key，SkipList和平衡树的时间复杂度都为O(log n)，大体相当；而哈希表在保持较低的哈希值冲突概率的前提下，查找时间复杂度接近O(1)，性能更高一些。所以我们平常使用的各种Map或dictionary结构，大都是基于哈希表实现的。
    - 从算法实现难度上来比较，SkipList比平衡树要简单得多。

### immutable Memtable

memtable的容量到达阈值时，便会转换成一个不可修改的memtable，也称为immutable memtable。这两者的结构定义完全一样，区别只是immutable memtable是只读的。当一个immutable memtable被创建时，leveldb的后台压缩进程便会将利用其中的内容，创建一个sstable，持久化到磁盘文件中。

### Log

前面说过，LevelDB是基于WAL的，所以这里的log就是在写操作过程中率先写入的组件，当以下异常情况发生时，均可以通过日志文件进行恢复：

1. 写log期间进程异常
2. 写log完成，写内存未完成；
3. write动作完成（即log、内存写入都完成）后，进程异常；
4. Immutable Memtable持久化过程中进程异常
5. 其他压缩异常（较为复杂，首先不在这里介绍）

当第一类情况发生时，**数据库重启读取log时，发现异常日志数据，抛弃该条日志数据，即视作这次用户写入失败，保障了数据库的一致性**；

当第二类，第三类，第四类情况发生了，均可以通过redo日志文件中记录的写入操作完成数据库的恢复。

每次日志的写操作都是一次**顺序写**，因此写效率高，整体写入性能较好。

此外，LevelDB的**用户写操作的原子性**同样通过日志来实现。

### sstable

**即持久化到硬盘的数据结构**

除了某些元数据文件，LevelDB的数据主要都是通过sstable来进行存储。

虽然在内存中，所有的数据都是按序排列的，但是当多个Memtable数据持久化到磁盘后，对应的不同的sstable之间是存在**交集**的，在读操作时，需要对所有的sstable文件进行遍历，严重影响了读取效率。因此leveldb后台会“定期“整合这些sstable文件，该过程也称为**compaction**。随着compaction的进行，sstable文件在逻辑上被分成若干层，由内存数据直接dump出来的文件称为level 0层文件，后期整合而成的文件为level i 层文件，这也是leveldb这个名字的由来。

注意，所有的sstable文件本身的内容是不可修改的，这种设计哲学为leveldb带来了许多优势，简化了很多设计。

### manifest

leveldb中有个版本的概念，一个版本中主要记录了每一层中所有文件的元数据，元数据包括（1）文件大小（2）最大key值（3）最小key值。该版本信息十分关键，除了在查找数据时，利用维护的每个文件的最大／小key值来**加快查找**，还在其中维护了一些进行compaction的统计值，来控制compaction的进行。

当每次**compaction完成**（或者换一种更容易理解的说法，当每次sstable文件有新增或者减少），leveldb都会创建一个新的version，创建的规则是:

`versionNew = versionOld + versionEdit`

versionEdit指代的是基于旧版本的基础上，变化的内容（例如新增或删除了某些sstable文件）。

**manifest文件就是用来记录这些versionEdit信息的**。一个versionEdit数据，会被编码成一条记录，写入manifest文件中。例如下图便是一个manifest文件的示意图，其中包含了3条versionEdit记录，每条记录包括（1）新增哪些sst文件（2）删除哪些sst文件（3）当前compaction的下标（4）日志文件编号（5）操作seqNumber等信息。通过这些信息，leveldb便可以在启动时，基于一个空的version，不断增加这些记录，最终得到一个上次运行结束时的版本信息。

![manifest](./pics/manifest.jpeg)

### current

这个文件的内容只有一个信息，**就是记载当前的manifest文件名**。

因为每次leveldb启动时，都会创建一个新的Manifest文件。因此数据目录可能会存在多个Manifest文件。Current则用来指出哪个Manifest文件才是我们关心的那个Manifest文件。

## 读写操作

### 写操作

![SkipList_2](./pics/SkipList_5.png)

首先我们要确认的是，LevelDB是一个基于**WAL**（**Write-ahead Log**）的存储系统，即先写日志数据，后写用户数据，这样就可以保证用户数据的持久化。在数据库意外宕机时，可以利用WAL恢复到宕机前的状态。

leveldb对外提供的写入接口有：（1）Put（2）Delete两种。这两种本质对应同一种操作，Delete操作同样会被转换成一个value为空的Put操作。

除此以外，leveldb还提供了一个批量处理的工具Batch，用户可以依据Batch来完成批量的数据库更新操作，且这些操作是原子性的。

### batch结构

无论是Put/Del操作，还是批量操作，底层都会为这些操作创建一个batch实例作为一个数据库操作的最小执行单元。因此首先介绍一下batch的组织结构。

![img](./pics/batch.jpeg)

在batch中，每一条数据项都按照上图格式进行编码。每条数据项编码后的第一位是这条数据项的类型（更**新还是删除**），之后是数据项key的长度，数据项key的内容；若该数据项不是删除操作，则再加上value的长度，value的内容。

batch中会维护一个size值，用于表示其中包含的数据量的大小。**该size值为所有数据项key与value长度的累加**，以及每条数据项额外的8个字节。这8个字节用于存储一条数据项额外的一些信息。

